2025-08-25 14:18:26,830 - INFO - Running 10 runs for intersection scenario with selfish composition
2025-08-25 14:18:26,858 - INFO - Created intersection-v1 environment
2025-08-25 14:18:26,858 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:26,858 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:26,884 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:18:26,884 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:26,884 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:26,927 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:26,941 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:26,941 - INFO - Step 0/1000 completed
2025-08-25 14:18:27,002 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:27,002 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,002 - INFO - Simulation completed successfully
2025-08-25 14:18:27,038 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,038 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,039 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,081 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:18:27,082 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,082 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:27,099 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:27,108 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:27,108 - INFO - Step 0/1000 completed
2025-08-25 14:18:27,117 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:27,117 - INFO - Info: {'speed': 22.873389410778522, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.7873389410778522), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.07873389410778524),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,117 - INFO - Simulation completed successfully
2025-08-25 14:18:27,151 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,151 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,151 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,192 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:18:27,192 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,192 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:27,233 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:27,254 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:27,254 - INFO - Step 0/1000 completed
2025-08-25 14:18:27,276 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:27,276 - INFO - Info: {'speed': 12.756484381426949, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,277 - INFO - Simulation completed successfully
2025-08-25 14:18:27,310 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,310 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,310 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,343 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:18:27,343 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,343 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:27,360 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:27,372 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:27,372 - INFO - Step 0/1000 completed
2025-08-25 14:18:27,418 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:27,418 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,418 - INFO - Simulation completed successfully
2025-08-25 14:18:27,445 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,445 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,445 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,470 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:18:27,470 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,470 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:27,510 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:27,524 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:27,524 - INFO - Step 0/1000 completed
2025-08-25 14:18:27,558 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:27,558 - INFO - Info: {'speed': 12.455717242730856, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,558 - INFO - Simulation completed successfully
2025-08-25 14:18:27,592 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,592 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,592 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,617 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:18:27,617 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,618 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:27,635 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:27,647 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:27,647 - INFO - Step 0/1000 completed
2025-08-25 14:18:27,698 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:27,698 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,698 - INFO - Simulation completed successfully
2025-08-25 14:18:27,725 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,725 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,725 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,750 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:18:27,750 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,750 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:27,782 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:27,790 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:27,790 - INFO - Step 0/1000 completed
2025-08-25 14:18:27,822 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:27,822 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,822 - INFO - Simulation completed successfully
2025-08-25 14:18:27,856 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,856 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,856 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,882 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:18:27,882 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,882 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:27,907 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:27,919 - INFO - [EGO] step=0 speed=4.4408045811768035 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:18:27,920 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:18:27,920 - INFO - Info: {'speed': 4.4408045811768035, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:27,920 - INFO - Simulation completed successfully
2025-08-25 14:18:27,946 - INFO - Created intersection-v1 environment
2025-08-25 14:18:27,946 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:27,946 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:27,988 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:18:27,988 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:27,988 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:28,038 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:28,059 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:28,059 - INFO - Step 0/1000 completed
2025-08-25 14:18:28,084 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:28,084 - INFO - Info: {'speed': 14.80764637164484, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:28,085 - INFO - Simulation completed successfully
2025-08-25 14:18:28,136 - INFO - Created intersection-v1 environment
2025-08-25 14:18:28,136 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:28,136 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:28,162 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:18:28,162 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:28,162 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:28,186 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:28,200 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:28,200 - INFO - Step 0/1000 completed
2025-08-25 14:18:28,254 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:28,254 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:28,255 - INFO - Simulation completed successfully
2025-08-25 14:18:28,255 - INFO - Running 10 runs for intersection scenario with cooperative composition
2025-08-25 14:18:28,281 - INFO - Created intersection-v1 environment
2025-08-25 14:18:28,281 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:28,281 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:28,307 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:28,307 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:28,307 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:28,347 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:28,361 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:28,361 - INFO - Step 0/1000 completed
2025-08-25 14:18:28,444 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:28,444 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:28,445 - INFO - Simulation completed successfully
2025-08-25 14:18:28,478 - INFO - Created intersection-v1 environment
2025-08-25 14:18:28,478 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:28,478 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:28,520 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:28,520 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:28,520 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:28,538 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:28,547 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:28,547 - INFO - Step 0/1000 completed
2025-08-25 14:18:28,565 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:28,565 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:28,565 - INFO - Simulation completed successfully
2025-08-25 14:18:28,607 - INFO - Created intersection-v1 environment
2025-08-25 14:18:28,608 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:28,608 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:28,649 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:28,649 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:28,649 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:28,690 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:28,711 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:28,711 - INFO - Step 0/1000 completed
2025-08-25 14:18:28,733 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:28,733 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:28,733 - INFO - Simulation completed successfully
2025-08-25 14:18:28,759 - INFO - Created intersection-v1 environment
2025-08-25 14:18:28,759 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:28,759 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:28,792 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:28,792 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:28,792 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:28,809 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:28,820 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:28,820 - INFO - Step 0/1000 completed
2025-08-25 14:18:28,868 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:28,868 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:28,868 - INFO - Simulation completed successfully
2025-08-25 14:18:28,913 - INFO - Created intersection-v1 environment
2025-08-25 14:18:28,913 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:28,913 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:28,939 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:28,939 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:28,939 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:28,979 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:28,993 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:28,993 - INFO - Step 0/1000 completed
2025-08-25 14:18:29,025 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:29,025 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 14:18:29,026 - INFO - Simulation completed successfully
2025-08-25 14:18:29,059 - INFO - Created intersection-v1 environment
2025-08-25 14:18:29,059 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:29,060 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:29,085 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:29,085 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:29,086 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:29,103 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:29,114 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:29,114 - INFO - Step 0/1000 completed
2025-08-25 14:18:29,187 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:29,187 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:29,187 - INFO - Simulation completed successfully
2025-08-25 14:18:29,248 - INFO - Created intersection-v1 environment
2025-08-25 14:18:29,248 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:29,248 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:29,273 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:29,273 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:29,274 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:29,305 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:29,314 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:29,314 - INFO - Step 0/1000 completed
2025-08-25 14:18:29,357 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:29,357 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:29,358 - INFO - Simulation completed successfully
2025-08-25 14:18:29,409 - INFO - Created intersection-v1 environment
2025-08-25 14:18:29,409 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:29,409 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:29,435 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:29,435 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:29,435 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:29,460 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:29,473 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:18:29,473 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:18:29,473 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:29,473 - INFO - Simulation completed successfully
2025-08-25 14:18:29,499 - INFO - Created intersection-v1 environment
2025-08-25 14:18:29,499 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:29,499 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:29,541 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:29,541 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:29,541 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:29,591 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:29,612 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:29,612 - INFO - Step 0/1000 completed
2025-08-25 14:18:29,637 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:29,637 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:18:29,638 - INFO - Simulation completed successfully
2025-08-25 14:18:29,664 - INFO - Created intersection-v1 environment
2025-08-25 14:18:29,664 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:29,664 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:29,690 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:29,690 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:29,690 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:29,714 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:29,728 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:29,729 - INFO - Step 0/1000 completed
2025-08-25 14:18:29,763 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:29,763 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:18:29,763 - INFO - Simulation completed successfully
2025-08-25 14:18:29,763 - INFO - Running 10 runs for intersection scenario with mixed composition
2025-08-25 14:18:29,790 - INFO - Created intersection-v1 environment
2025-08-25 14:18:29,790 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:29,790 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:29,815 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:18:29,815 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:29,815 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:29,855 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:29,869 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:29,870 - INFO - Step 0/1000 completed
2025-08-25 14:18:29,929 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:29,930 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:29,930 - INFO - Simulation completed successfully
2025-08-25 14:18:29,957 - INFO - Created intersection-v1 environment
2025-08-25 14:18:29,957 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:29,957 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:29,998 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:29,998 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:29,998 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:30,015 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:30,024 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:30,024 - INFO - Step 0/1000 completed
2025-08-25 14:18:30,043 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:30,043 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:30,043 - INFO - Simulation completed successfully
2025-08-25 14:18:30,064 - INFO - Created intersection-v1 environment
2025-08-25 14:18:30,064 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:30,064 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:30,107 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:30,107 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:30,107 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:30,150 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:30,171 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:30,171 - INFO - Step 0/1000 completed
2025-08-25 14:18:30,193 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:30,194 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:30,194 - INFO - Simulation completed successfully
2025-08-25 14:18:30,220 - INFO - Created intersection-v1 environment
2025-08-25 14:18:30,220 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:30,220 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:30,253 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:30,253 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:30,253 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:30,270 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:30,282 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:30,282 - INFO - Step 0/1000 completed
2025-08-25 14:18:30,329 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:30,329 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:30,329 - INFO - Simulation completed successfully
2025-08-25 14:18:30,355 - INFO - Created intersection-v1 environment
2025-08-25 14:18:30,355 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:30,355 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:30,380 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:18:30,380 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:30,380 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:30,421 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:30,435 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:30,435 - INFO - Step 0/1000 completed
2025-08-25 14:18:30,470 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:30,470 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 14:18:30,470 - INFO - Simulation completed successfully
2025-08-25 14:18:30,492 - INFO - Created intersection-v1 environment
2025-08-25 14:18:30,492 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:30,492 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:30,519 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:30,520 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:30,520 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:30,538 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:30,551 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:30,551 - INFO - Step 0/1000 completed
2025-08-25 14:18:30,614 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:30,614 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:30,615 - INFO - Simulation completed successfully
2025-08-25 14:18:30,646 - INFO - Created intersection-v1 environment
2025-08-25 14:18:30,647 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:30,647 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:30,675 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:30,675 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:30,675 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:30,709 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:30,719 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:30,719 - INFO - Step 0/1000 completed
2025-08-25 14:18:30,766 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:30,766 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:30,767 - INFO - Simulation completed successfully
2025-08-25 14:18:30,818 - INFO - Created intersection-v1 environment
2025-08-25 14:18:30,818 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:30,818 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:30,848 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:18:30,848 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:30,848 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:30,875 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:30,888 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:18:30,888 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:18:30,888 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:30,888 - INFO - Simulation completed successfully
2025-08-25 14:18:30,915 - INFO - Created intersection-v1 environment
2025-08-25 14:18:30,915 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:30,915 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:30,957 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:18:30,957 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:30,957 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:31,006 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:31,027 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:31,027 - INFO - Step 0/1000 completed
2025-08-25 14:18:31,053 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:31,054 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:18:31,054 - INFO - Simulation completed successfully
2025-08-25 14:18:31,088 - INFO - Created intersection-v1 environment
2025-08-25 14:18:31,088 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:31,088 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:31,114 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:18:31,114 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:31,114 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:31,138 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:31,152 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:31,152 - INFO - Step 0/1000 completed
2025-08-25 14:18:31,207 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:31,207 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:31,207 - INFO - Simulation completed successfully
2025-08-25 14:18:31,207 - INFO - Saving aggregated results...
2025-08-25 14:18:31,220 - INFO - Aggregated results saved to results/highway_stats.csv
2025-08-25 14:18:31,220 - INFO - Generating comparison plots...
2025-08-25 14:18:34,090 - INFO - Generated 6 plots in /Users/shayvasilisky/Documents/Personal/TASP/Second Year/Semester B/רובוטים קוגניטיביים/Project CC_V2/social_law_simulation/plots
2025-08-25 14:18:34,090 - INFO -   - intersection_average_speed.png
2025-08-25 14:18:34,090 - INFO -   - intersection_collisions.png
2025-08-25 14:18:34,090 - INFO -   - intersection_acceleration_stability.png
2025-08-25 14:18:34,090 - INFO -   - combined_efficiency_comparison.png
2025-08-25 14:18:34,090 - INFO -   - combined_safety_comparison.png
2025-08-25 14:18:34,090 - INFO -   - summary_dashboard.png
