2025-08-25 14:18:52,896 - INFO - Running 10 runs for intersection scenario with selfish composition
2025-08-25 14:18:52,939 - INFO - Created intersection-v1 environment
2025-08-25 14:18:52,939 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:52,939 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:52,957 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/3 (composition=selfish)
2025-08-25 14:18:52,957 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:52,957 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:53,016 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:53,034 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:53,034 - INFO - Step 0/1000 completed
2025-08-25 14:18:53,055 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:53,055 - INFO - Info: {'speed': 24.561958168995417, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.9561958168995417), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.09561958168995417),), 'agents_terminated': (True,)}
2025-08-25 14:18:53,055 - INFO - Simulation completed successfully
2025-08-25 14:18:53,097 - INFO - Created intersection-v1 environment
2025-08-25 14:18:53,097 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:53,097 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:53,130 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:18:53,130 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:53,130 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:53,171 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:53,189 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:53,189 - INFO - Step 0/1000 completed
2025-08-25 14:18:53,209 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:53,209 - INFO - Info: {'speed': 19.818837751309246, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.4818837751309246), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04818837751309246),), 'agents_terminated': (True,)}
2025-08-25 14:18:53,209 - INFO - Simulation completed successfully
2025-08-25 14:18:53,229 - INFO - Created intersection-v1 environment
2025-08-25 14:18:53,229 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:53,229 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:53,271 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:18:53,271 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:53,271 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:53,295 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:53,307 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:53,307 - INFO - Step 0/1000 completed
2025-08-25 14:18:53,355 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:53,355 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:53,355 - INFO - Simulation completed successfully
2025-08-25 14:18:53,398 - INFO - Created intersection-v1 environment
2025-08-25 14:18:53,398 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:53,398 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:53,451 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:18:53,451 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:53,451 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:53,492 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:53,510 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:53,510 - INFO - Step 0/1000 completed
2025-08-25 14:18:53,581 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:53,581 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:53,582 - INFO - Simulation completed successfully
2025-08-25 14:18:53,601 - INFO - Created intersection-v1 environment
2025-08-25 14:18:53,601 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:53,601 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:53,619 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/3 (composition=selfish)
2025-08-25 14:18:53,619 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:53,619 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:53,668 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:53,690 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:53,690 - INFO - Step 0/1000 completed
2025-08-25 14:18:53,716 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:53,716 - INFO - Info: {'speed': 15.938712641708477, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.09387126417084772), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.00938712641708476),), 'agents_terminated': (True,)}
2025-08-25 14:18:53,716 - INFO - Simulation completed successfully
2025-08-25 14:18:53,729 - INFO - Created intersection-v1 environment
2025-08-25 14:18:53,730 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:53,730 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:53,755 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/3 (composition=selfish)
2025-08-25 14:18:53,755 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:53,755 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:53,780 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:53,794 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:53,794 - INFO - Step 0/1000 completed
2025-08-25 14:18:53,847 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:53,848 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:53,848 - INFO - Simulation completed successfully
2025-08-25 14:18:53,867 - INFO - Created intersection-v1 environment
2025-08-25 14:18:53,867 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:53,867 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:53,909 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:18:53,909 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:53,909 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:53,958 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:53,976 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:53,976 - INFO - Step 0/1000 completed
2025-08-25 14:18:54,019 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:54,019 - INFO - Info: {'speed': 10.4825409789243, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:18:54,019 - INFO - Simulation completed successfully
2025-08-25 14:18:54,052 - INFO - Created intersection-v1 environment
2025-08-25 14:18:54,052 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:54,052 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:54,085 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:18:54,085 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:54,085 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:54,096 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:54,102 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:54,102 - INFO - Step 0/1000 completed
2025-08-25 14:18:54,120 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:54,120 - INFO - Info: {'speed': 14.681592011857107, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:18:54,120 - INFO - Simulation completed successfully
2025-08-25 14:18:54,162 - INFO - Created intersection-v1 environment
2025-08-25 14:18:54,162 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:54,162 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:54,181 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/2 (composition=selfish)
2025-08-25 14:18:54,181 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:54,181 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:54,212 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:54,226 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:54,226 - INFO - Step 0/1000 completed
2025-08-25 14:18:54,290 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:54,291 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:54,291 - INFO - Simulation completed successfully
2025-08-25 14:18:54,324 - INFO - Created intersection-v1 environment
2025-08-25 14:18:54,324 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:54,324 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:18:54,357 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:18:54,357 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:54,357 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:18:54,381 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:54,390 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:54,390 - INFO - Step 0/1000 completed
2025-08-25 14:18:54,426 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:54,426 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:54,426 - INFO - Simulation completed successfully
2025-08-25 14:18:54,426 - INFO - Running 10 runs for intersection scenario with cooperative composition
2025-08-25 14:18:54,460 - INFO - Created intersection-v1 environment
2025-08-25 14:18:54,460 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:54,460 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:54,478 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:54,479 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:54,479 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:54,537 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:54,554 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:54,554 - INFO - Step 0/1000 completed
2025-08-25 14:18:54,602 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:54,602 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:54,603 - INFO - Simulation completed successfully
2025-08-25 14:18:54,629 - INFO - Created intersection-v1 environment
2025-08-25 14:18:54,629 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:54,629 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:54,662 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:54,662 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:54,662 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:54,703 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:54,721 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:54,721 - INFO - Step 0/1000 completed
2025-08-25 14:18:54,763 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:54,763 - INFO - Info: {'speed': 7.725467974079904, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:54,763 - INFO - Simulation completed successfully
2025-08-25 14:18:54,797 - INFO - Created intersection-v1 environment
2025-08-25 14:18:54,797 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:54,797 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:54,838 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:54,839 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:54,839 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:54,864 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:54,875 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:54,875 - INFO - Step 0/1000 completed
2025-08-25 14:18:54,907 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:54,907 - INFO - Info: {'speed': 14.101220212980753, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:54,907 - INFO - Simulation completed successfully
2025-08-25 14:18:54,941 - INFO - Created intersection-v1 environment
2025-08-25 14:18:54,941 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:54,941 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:54,991 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:54,991 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:54,991 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:55,032 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:55,049 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:55,049 - INFO - Step 0/1000 completed
2025-08-25 14:18:55,149 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:55,149 - INFO - Info: {'speed': 24.852528716562727, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9852528716562727), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:55,149 - INFO - Simulation completed successfully
2025-08-25 14:18:55,175 - INFO - Created intersection-v1 environment
2025-08-25 14:18:55,175 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:55,175 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:55,193 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:55,194 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:55,194 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:55,242 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:55,263 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:55,263 - INFO - Step 0/1000 completed
2025-08-25 14:18:55,288 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:55,288 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:18:55,289 - INFO - Simulation completed successfully
2025-08-25 14:18:55,314 - INFO - Created intersection-v1 environment
2025-08-25 14:18:55,314 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:55,314 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:55,339 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:55,339 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:55,340 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:55,364 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:55,379 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:55,379 - INFO - Step 0/1000 completed
2025-08-25 14:18:55,453 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:55,453 - INFO - Info: {'speed': 24.876752111742448, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9876752111742448), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:55,453 - INFO - Simulation completed successfully
2025-08-25 14:18:55,504 - INFO - Created intersection-v1 environment
2025-08-25 14:18:55,504 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:55,504 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:55,546 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:55,546 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:55,546 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:55,595 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:55,612 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:55,612 - INFO - Step 0/1000 completed
2025-08-25 14:18:55,656 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:55,656 - INFO - Info: {'speed': 10.671407141752367, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:55,656 - INFO - Simulation completed successfully
2025-08-25 14:18:55,683 - INFO - Created intersection-v1 environment
2025-08-25 14:18:55,683 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:55,683 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:55,715 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:55,715 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:55,715 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:55,726 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:55,732 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:55,732 - INFO - Step 0/1000 completed
2025-08-25 14:18:55,751 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:55,751 - INFO - Info: {'speed': 13.153708164644879, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:55,751 - INFO - Simulation completed successfully
2025-08-25 14:18:55,802 - INFO - Created intersection-v1 environment
2025-08-25 14:18:55,802 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:55,802 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:55,821 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:55,821 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:55,821 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:55,852 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:55,867 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:55,867 - INFO - Step 0/1000 completed
2025-08-25 14:18:55,954 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:55,954 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:55,954 - INFO - Simulation completed successfully
2025-08-25 14:18:55,988 - INFO - Created intersection-v1 environment
2025-08-25 14:18:55,988 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:55,988 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:18:56,021 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:18:56,021 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:56,021 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:18:56,045 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:56,054 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:56,054 - INFO - Step 0/1000 completed
2025-08-25 14:18:56,106 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:56,106 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:56,106 - INFO - Simulation completed successfully
2025-08-25 14:18:56,106 - INFO - Running 10 runs for intersection scenario with mixed composition
2025-08-25 14:18:56,140 - INFO - Created intersection-v1 environment
2025-08-25 14:18:56,140 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:56,140 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:56,158 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/1 (composition=mixed)
2025-08-25 14:18:56,159 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:56,159 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:56,217 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:56,234 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:56,234 - INFO - Step 0/1000 completed
2025-08-25 14:18:56,281 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:56,281 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:56,282 - INFO - Simulation completed successfully
2025-08-25 14:18:56,323 - INFO - Created intersection-v1 environment
2025-08-25 14:18:56,323 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:56,323 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:56,355 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:56,355 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:56,355 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:56,396 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:56,414 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:56,414 - INFO - Step 0/1000 completed
2025-08-25 14:18:56,433 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:56,433 - INFO - Info: {'speed': 19.818837751309246, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.4818837751309246), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04818837751309246),), 'agents_terminated': (True,)}
2025-08-25 14:18:56,433 - INFO - Simulation completed successfully
2025-08-25 14:18:56,459 - INFO - Created intersection-v1 environment
2025-08-25 14:18:56,459 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:56,459 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:56,501 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:56,501 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:56,501 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:56,526 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:56,538 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:56,538 - INFO - Step 0/1000 completed
2025-08-25 14:18:56,569 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:56,569 - INFO - Info: {'speed': 14.101220212980753, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:56,570 - INFO - Simulation completed successfully
2025-08-25 14:18:56,612 - INFO - Created intersection-v1 environment
2025-08-25 14:18:56,612 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:56,612 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:56,662 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:56,662 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:56,662 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:56,702 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:56,719 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:56,719 - INFO - Step 0/1000 completed
2025-08-25 14:18:56,791 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:56,791 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:56,791 - INFO - Simulation completed successfully
2025-08-25 14:18:56,811 - INFO - Created intersection-v1 environment
2025-08-25 14:18:56,811 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:56,811 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:56,829 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/1 (composition=mixed)
2025-08-25 14:18:56,829 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:56,829 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:56,878 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:56,898 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:56,898 - INFO - Step 0/1000 completed
2025-08-25 14:18:56,924 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:18:56,924 - INFO - Info: {'speed': 15.938712641708477, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.09387126417084772), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.00938712641708476),), 'agents_terminated': (True,)}
2025-08-25 14:18:56,924 - INFO - Simulation completed successfully
2025-08-25 14:18:56,957 - INFO - Created intersection-v1 environment
2025-08-25 14:18:56,958 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:56,958 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:56,983 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/1 (composition=mixed)
2025-08-25 14:18:56,983 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:56,983 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:57,008 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:57,022 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:57,022 - INFO - Step 0/1000 completed
2025-08-25 14:18:57,097 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:57,097 - INFO - Info: {'speed': 24.876752111742448, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9876752111742448), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:57,097 - INFO - Simulation completed successfully
2025-08-25 14:18:57,123 - INFO - Created intersection-v1 environment
2025-08-25 14:18:57,123 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:57,123 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:57,165 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:18:57,166 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:57,166 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:57,215 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:57,233 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:57,233 - INFO - Step 0/1000 completed
2025-08-25 14:18:57,275 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:57,276 - INFO - Info: {'speed': 10.4825409789243, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:18:57,276 - INFO - Simulation completed successfully
2025-08-25 14:18:57,326 - INFO - Created intersection-v1 environment
2025-08-25 14:18:57,326 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:57,326 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:57,358 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:18:57,358 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:57,358 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:57,370 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:57,376 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:57,376 - INFO - Step 0/1000 completed
2025-08-25 14:18:57,394 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:18:57,394 - INFO - Info: {'speed': 13.153708164644879, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:57,394 - INFO - Simulation completed successfully
2025-08-25 14:18:57,427 - INFO - Created intersection-v1 environment
2025-08-25 14:18:57,427 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:57,428 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:57,446 - INFO - Population overrides: cooperative_set=0/1, baseline_set=0/1 (composition=mixed)
2025-08-25 14:18:57,446 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:18:57,446 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:18:57,478 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:57,492 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:57,492 - INFO - Step 0/1000 completed
2025-08-25 14:18:57,578 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:18:57,578 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:57,578 - INFO - Simulation completed successfully
2025-08-25 14:18:57,598 - INFO - Created intersection-v1 environment
2025-08-25 14:18:57,598 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:18:57,598 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:18:57,631 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:18:57,631 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:18:57,631 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:18:57,656 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:18:57,664 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:18:57,664 - INFO - Step 0/1000 completed
2025-08-25 14:18:57,700 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:18:57,700 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:18:57,701 - INFO - Simulation completed successfully
2025-08-25 14:18:57,701 - INFO - Saving aggregated results...
2025-08-25 14:18:57,710 - INFO - Aggregated results saved to results/highway_stats.csv
2025-08-25 14:18:57,710 - INFO - Generating comparison plots...
2025-08-25 14:19:00,558 - INFO - Generated 6 plots in /Users/shayvasilisky/Documents/Personal/TASP/Second Year/Semester B/רובוטים קוגניטיביים/Project CC_V2/social_law_simulation/plots
2025-08-25 14:19:00,558 - INFO -   - intersection_average_speed.png
2025-08-25 14:19:00,558 - INFO -   - intersection_collisions.png
2025-08-25 14:19:00,558 - INFO -   - intersection_acceleration_stability.png
2025-08-25 14:19:00,558 - INFO -   - combined_efficiency_comparison.png
2025-08-25 14:19:00,558 - INFO -   - combined_safety_comparison.png
2025-08-25 14:19:00,558 - INFO -   - summary_dashboard.png
