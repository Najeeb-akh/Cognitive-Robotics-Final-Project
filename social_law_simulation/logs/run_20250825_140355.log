2025-08-25 14:03:55,305 - INFO - Running 10 runs for intersection scenario with selfish composition
2025-08-25 14:03:55,332 - INFO - Created intersection-v1 environment
2025-08-25 14:03:55,333 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:55,359 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:03:55,359 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:55,359 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:55,400 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:55,415 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:55,415 - INFO - Step 0/1000 completed
2025-08-25 14:03:55,475 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:55,475 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:55,475 - INFO - Simulation completed successfully
2025-08-25 14:03:55,518 - INFO - Created intersection-v1 environment
2025-08-25 14:03:55,518 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:55,559 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:03:55,559 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:55,559 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:55,576 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:55,585 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:55,585 - INFO - Step 0/1000 completed
2025-08-25 14:03:55,594 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:03:55,594 - INFO - Info: {'speed': 22.873389410778522, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.7873389410778522), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.07873389410778524),), 'agents_terminated': (True,)}
2025-08-25 14:03:55,595 - INFO - Simulation completed successfully
2025-08-25 14:03:55,646 - INFO - Created intersection-v1 environment
2025-08-25 14:03:55,646 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:55,687 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:03:55,687 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:55,687 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:55,729 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:55,751 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:55,752 - INFO - Step 0/1000 completed
2025-08-25 14:03:55,774 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:03:55,774 - INFO - Info: {'speed': 12.756484381426949, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:55,774 - INFO - Simulation completed successfully
2025-08-25 14:03:55,826 - INFO - Created intersection-v1 environment
2025-08-25 14:03:55,826 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:55,859 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:03:55,859 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:55,859 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:55,877 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:55,888 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:55,888 - INFO - Step 0/1000 completed
2025-08-25 14:03:55,935 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:55,935 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:55,936 - INFO - Simulation completed successfully
2025-08-25 14:03:55,979 - INFO - Created intersection-v1 environment
2025-08-25 14:03:55,980 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:56,004 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:03:56,005 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:56,005 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:56,045 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:56,059 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:56,059 - INFO - Step 0/1000 completed
2025-08-25 14:03:56,091 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:03:56,091 - INFO - Info: {'speed': 12.455717242730856, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:03:56,092 - INFO - Simulation completed successfully
2025-08-25 14:03:56,125 - INFO - Created intersection-v1 environment
2025-08-25 14:03:56,125 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:56,151 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:03:56,151 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:56,151 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:56,168 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:56,179 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:56,180 - INFO - Step 0/1000 completed
2025-08-25 14:03:56,231 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:56,231 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:56,231 - INFO - Simulation completed successfully
2025-08-25 14:03:56,244 - INFO - Created intersection-v1 environment
2025-08-25 14:03:56,244 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:56,269 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:03:56,270 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:56,270 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:56,302 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:56,310 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:56,310 - INFO - Step 0/1000 completed
2025-08-25 14:03:56,342 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:56,342 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:56,342 - INFO - Simulation completed successfully
2025-08-25 14:03:56,385 - INFO - Created intersection-v1 environment
2025-08-25 14:03:56,385 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:56,411 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:03:56,411 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:56,411 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:56,437 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:56,449 - INFO - [EGO] step=0 speed=4.4408045811768035 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:03:56,449 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:03:56,449 - INFO - Info: {'speed': 4.4408045811768035, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:56,449 - INFO - Simulation completed successfully
2025-08-25 14:03:56,491 - INFO - Created intersection-v1 environment
2025-08-25 14:03:56,492 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:56,533 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:03:56,533 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:56,533 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:56,583 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:56,604 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:56,604 - INFO - Step 0/1000 completed
2025-08-25 14:03:56,629 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:03:56,630 - INFO - Info: {'speed': 14.80764637164484, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:56,630 - INFO - Simulation completed successfully
2025-08-25 14:03:56,672 - INFO - Created intersection-v1 environment
2025-08-25 14:03:56,672 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:56,698 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:03:56,698 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:56,698 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:03:56,722 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:56,736 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:56,736 - INFO - Step 0/1000 completed
2025-08-25 14:03:56,792 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:56,792 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:56,792 - INFO - Simulation completed successfully
2025-08-25 14:03:56,792 - INFO - Running 10 runs for intersection scenario with cooperative composition
2025-08-25 14:03:56,820 - INFO - Created intersection-v1 environment
2025-08-25 14:03:56,820 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:56,845 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:56,846 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:56,846 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:56,887 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:56,901 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:56,901 - INFO - Step 0/1000 completed
2025-08-25 14:03:56,985 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:03:56,985 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:56,985 - INFO - Simulation completed successfully
2025-08-25 14:03:57,012 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,012 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,053 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,053 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,053 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,070 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:57,079 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:57,079 - INFO - Step 0/1000 completed
2025-08-25 14:03:57,097 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:03:57,097 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:57,097 - INFO - Simulation completed successfully
2025-08-25 14:03:57,130 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,131 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,172 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,172 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,172 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,212 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:57,233 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:57,233 - INFO - Step 0/1000 completed
2025-08-25 14:03:57,256 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:03:57,256 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:57,256 - INFO - Simulation completed successfully
2025-08-25 14:03:57,290 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,291 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,323 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,323 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,323 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,341 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:57,353 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:57,353 - INFO - Step 0/1000 completed
2025-08-25 14:03:57,399 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:57,399 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:57,400 - INFO - Simulation completed successfully
2025-08-25 14:03:57,426 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,426 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,451 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,451 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,451 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,491 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:57,505 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:57,505 - INFO - Step 0/1000 completed
2025-08-25 14:03:57,537 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:03:57,537 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 14:03:57,537 - INFO - Simulation completed successfully
2025-08-25 14:03:57,545 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,545 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,570 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,570 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,570 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,588 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:57,599 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:57,599 - INFO - Step 0/1000 completed
2025-08-25 14:03:57,672 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:03:57,672 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:57,672 - INFO - Simulation completed successfully
2025-08-25 14:03:57,698 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,698 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,724 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,724 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,724 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,756 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:57,764 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:57,764 - INFO - Step 0/1000 completed
2025-08-25 14:03:57,807 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:03:57,807 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:57,808 - INFO - Simulation completed successfully
2025-08-25 14:03:57,827 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,827 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,853 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,853 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,853 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,878 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:57,891 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:03:57,891 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:03:57,891 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:57,891 - INFO - Simulation completed successfully
2025-08-25 14:03:57,899 - INFO - Created intersection-v1 environment
2025-08-25 14:03:57,899 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:57,941 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:57,941 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:57,941 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:57,991 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,011 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,011 - INFO - Step 0/1000 completed
2025-08-25 14:03:58,036 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:03:58,036 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:03:58,037 - INFO - Simulation completed successfully
2025-08-25 14:03:58,062 - INFO - Created intersection-v1 environment
2025-08-25 14:03:58,062 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:58,088 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:03:58,088 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:58,088 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:03:58,112 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,127 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,127 - INFO - Step 0/1000 completed
2025-08-25 14:03:58,161 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:03:58,161 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:03:58,161 - INFO - Simulation completed successfully
2025-08-25 14:03:58,161 - INFO - Running 10 runs for intersection scenario with mixed composition
2025-08-25 14:03:58,203 - INFO - Created intersection-v1 environment
2025-08-25 14:03:58,204 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:58,229 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:03:58,229 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:58,229 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:03:58,270 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,284 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,284 - INFO - Step 0/1000 completed
2025-08-25 14:03:58,344 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:58,344 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:58,345 - INFO - Simulation completed successfully
2025-08-25 14:03:58,378 - INFO - Created intersection-v1 environment
2025-08-25 14:03:58,378 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:58,419 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:03:58,420 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:58,420 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:03:58,437 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,447 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,447 - INFO - Step 0/1000 completed
2025-08-25 14:03:58,465 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:03:58,465 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:58,465 - INFO - Simulation completed successfully
2025-08-25 14:03:58,492 - INFO - Created intersection-v1 environment
2025-08-25 14:03:58,492 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:58,533 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:03:58,533 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:58,533 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:03:58,574 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,595 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,595 - INFO - Step 0/1000 completed
2025-08-25 14:03:58,617 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:03:58,617 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:58,617 - INFO - Simulation completed successfully
2025-08-25 14:03:58,650 - INFO - Created intersection-v1 environment
2025-08-25 14:03:58,650 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:58,683 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:03:58,683 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:58,683 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:03:58,701 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,712 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,712 - INFO - Step 0/1000 completed
2025-08-25 14:03:58,758 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:58,758 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:58,758 - INFO - Simulation completed successfully
2025-08-25 14:03:58,793 - INFO - Created intersection-v1 environment
2025-08-25 14:03:58,793 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:58,817 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:03:58,817 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:58,817 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:03:58,857 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,871 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,871 - INFO - Step 0/1000 completed
2025-08-25 14:03:58,903 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:03:58,903 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 14:03:58,904 - INFO - Simulation completed successfully
2025-08-25 14:03:58,938 - INFO - Created intersection-v1 environment
2025-08-25 14:03:58,938 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:58,964 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:03:58,964 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:58,964 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:03:58,983 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:58,994 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:58,994 - INFO - Step 0/1000 completed
2025-08-25 14:03:59,045 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:59,045 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:59,045 - INFO - Simulation completed successfully
2025-08-25 14:03:59,210 - INFO - Created intersection-v1 environment
2025-08-25 14:03:59,211 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:59,257 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:03:59,257 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:59,258 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:03:59,293 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:59,302 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:59,302 - INFO - Step 0/1000 completed
2025-08-25 14:03:59,348 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:03:59,348 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:59,348 - INFO - Simulation completed successfully
2025-08-25 14:03:59,377 - INFO - Created intersection-v1 environment
2025-08-25 14:03:59,377 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:59,408 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:03:59,408 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:59,408 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:03:59,436 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:59,451 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:03:59,451 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:03:59,451 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:59,451 - INFO - Simulation completed successfully
2025-08-25 14:03:59,488 - INFO - Created intersection-v1 environment
2025-08-25 14:03:59,488 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:59,537 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:03:59,537 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:03:59,537 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:03:59,591 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:59,614 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:59,614 - INFO - Step 0/1000 completed
2025-08-25 14:03:59,641 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:03:59,642 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:03:59,642 - INFO - Simulation completed successfully
2025-08-25 14:03:59,674 - INFO - Created intersection-v1 environment
2025-08-25 14:03:59,674 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:03:59,707 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:03:59,707 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:03:59,707 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:03:59,738 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:03:59,755 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:03:59,755 - INFO - Step 0/1000 completed
2025-08-25 14:03:59,813 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:03:59,813 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:03:59,813 - INFO - Simulation completed successfully
2025-08-25 14:03:59,813 - INFO - Saving aggregated results...
2025-08-25 14:03:59,825 - INFO - Aggregated results saved to results/highway_stats.csv
2025-08-25 14:03:59,825 - INFO - Generating comparison plots...
2025-08-25 14:04:02,882 - INFO - Generated 6 plots in /Users/shayvasilisky/Documents/Personal/TASP/Second Year/Semester B/רובוטים קוגניטיביים/Project CC_V2/social_law_simulation/plots
2025-08-25 14:04:02,882 - INFO -   - intersection_average_speed.png
2025-08-25 14:04:02,882 - INFO -   - intersection_collisions.png
2025-08-25 14:04:02,883 - INFO -   - intersection_acceleration_stability.png
2025-08-25 14:04:02,883 - INFO -   - combined_efficiency_comparison.png
2025-08-25 14:04:02,883 - INFO -   - combined_safety_comparison.png
2025-08-25 14:04:02,883 - INFO -   - summary_dashboard.png
