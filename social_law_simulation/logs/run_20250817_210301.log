2025-08-17 21:03:01,404 - INFO - Created SelfishPolicy for ego vehicle
2025-08-17 21:03:01,411 - INFO - Starting simulation with SelfishPolicy for 1000 steps
2025-08-17 21:03:01,582 - INFO - Step 0/1000 completed
2025-08-17 21:03:34,910 - INFO - Simulation ended early at step 199 - terminated: False, truncated: True
2025-08-17 21:03:34,910 - INFO - Info: {'speed': 20.000000000000014, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.3333333333333333, 'high_speed_reward': np.float64(1.4210854715202005e-15), 'on_road_reward': 1.0}}
2025-08-17 21:03:34,911 - INFO - Simulation completed successfully
2025-08-17 21:03:34,917 - INFO - Created CooperativePolicy for ego vehicle
2025-08-17 21:03:34,923 - INFO - Starting simulation with CooperativePolicy for 1000 steps
2025-08-17 21:03:35,100 - INFO - Step 0/1000 completed
2025-08-17 21:04:08,673 - INFO - Simulation ended early at step 199 - terminated: False, truncated: True
2025-08-17 21:04:08,673 - INFO - Info: {'speed': 20.000000000000014, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.6666666666666666, 'high_speed_reward': np.float64(1.4210854715202005e-15), 'on_road_reward': 1.0}}
2025-08-17 21:04:08,673 - INFO - Simulation completed successfully
2025-08-17 21:04:08,680 - INFO - Created CooperativePolicy for ego vehicle
2025-08-17 21:04:08,686 - INFO - Starting simulation with CooperativePolicy for 1000 steps
2025-08-17 21:04:08,859 - INFO - Step 0/1000 completed
2025-08-17 21:04:42,637 - INFO - Simulation ended early at step 199 - terminated: False, truncated: True
2025-08-17 21:04:42,638 - INFO - Info: {'speed': 20.000000000000014, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.3333333333333333, 'high_speed_reward': np.float64(1.4210854715202005e-15), 'on_road_reward': 1.0}}
2025-08-17 21:04:42,638 - INFO - Simulation completed successfully
2025-08-17 21:04:42,641 - INFO - Created SelfishPolicy for ego vehicle
2025-08-17 21:04:42,644 - INFO - Starting simulation with SelfishPolicy for 1000 steps
2025-08-17 21:04:42,649 - INFO - Step 0/1000 completed
2025-08-17 21:04:42,835 - INFO - Simulation ended early at step 42 - terminated: True, truncated: False
2025-08-17 21:04:42,835 - INFO - Info: {'speed': 15.17669135828414, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': True, 'right_lane_reward': 1.0, 'high_speed_reward': -0.482330864171586, 'lane_change_reward': False, 'merging_speed_reward': 0}}
2025-08-17 21:04:42,835 - INFO - Simulation completed successfully
2025-08-17 21:04:42,839 - INFO - Created CooperativePolicy for ego vehicle
2025-08-17 21:04:42,842 - INFO - Starting simulation with CooperativePolicy for 1000 steps
2025-08-17 21:04:42,847 - INFO - Step 0/1000 completed
2025-08-17 21:04:43,064 - INFO - Simulation ended early at step 49 - terminated: True, truncated: False
2025-08-17 21:04:43,064 - INFO - Info: {'speed': 20.00000000000346, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': False, 'right_lane_reward': 1.0, 'high_speed_reward': 3.460343123151688e-13, 'lane_change_reward': False, 'merging_speed_reward': 1.0095744780379499}}
2025-08-17 21:04:43,064 - INFO - Simulation completed successfully
2025-08-17 21:04:43,067 - INFO - Created CooperativePolicy for ego vehicle
2025-08-17 21:04:43,070 - INFO - Starting simulation with CooperativePolicy for 1000 steps
2025-08-17 21:04:43,074 - INFO - Step 0/1000 completed
2025-08-17 21:04:43,294 - INFO - Simulation ended early at step 49 - terminated: True, truncated: False
2025-08-17 21:04:43,294 - INFO - Info: {'speed': 20.00000000000346, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': False, 'right_lane_reward': 1.0, 'high_speed_reward': 3.460343123151688e-13, 'lane_change_reward': False, 'merging_speed_reward': 1.0095744780379499}}
2025-08-17 21:04:43,294 - INFO - Simulation completed successfully
2025-08-17 21:04:43,329 - INFO - Created intersection-v0 environment
2025-08-17 21:04:43,329 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-17 21:04:43,329 - INFO - Created IntersectionSelfishPolicy for ego vehicle
2025-08-17 21:04:43,365 - INFO - Starting simulation with IntersectionSelfishPolicy for 1000 steps
2025-08-17 21:04:43,380 - INFO - Step 0/1000 completed
2025-08-17 21:04:43,416 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-17 21:04:43,416 - INFO - Info: {'speed': 13.153708164644879, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-17 21:04:43,416 - INFO - Simulation completed successfully
2025-08-17 21:04:43,442 - INFO - Created intersection-v0 environment
2025-08-17 21:04:43,442 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-17 21:04:43,442 - INFO - Created IntersectionCooperativePolicy for ego vehicle
2025-08-17 21:04:43,476 - INFO - Starting simulation with IntersectionCooperativePolicy for 1000 steps
2025-08-17 21:04:43,489 - INFO - Step 0/1000 completed
2025-08-17 21:04:43,550 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-17 21:04:43,550 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-17 21:04:43,550 - INFO - Simulation completed successfully
2025-08-17 21:04:43,593 - INFO - Created intersection-v0 environment
2025-08-17 21:04:43,593 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-17 21:04:43,593 - INFO - Created IntersectionCooperativePolicy for ego vehicle
2025-08-17 21:04:43,621 - INFO - Starting simulation with IntersectionCooperativePolicy for 1000 steps
2025-08-17 21:04:43,635 - INFO - Step 0/1000 completed
2025-08-17 21:04:43,715 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-17 21:04:43,715 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-17 21:04:43,716 - INFO - Simulation completed successfully
2025-08-17 21:04:43,719 - INFO - Created roundabout-v0 environment
2025-08-17 21:04:43,719 - INFO - RoundaboutSelfishPolicy initialized
2025-08-17 21:04:43,719 - INFO - Created RoundaboutSelfishPolicy for ego vehicle
2025-08-17 21:04:43,723 - INFO - Starting simulation with RoundaboutSelfishPolicy for 1000 steps
2025-08-17 21:04:43,739 - INFO - Step 0/1000 completed
2025-08-17 21:04:43,757 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-17 21:04:43,757 - INFO - Info: {'speed': 8.764060590857493, 'crashed': True, 'action': 1, 'rewards': {'collision_reward': True, 'high_speed_reward': np.float64(0.0), 'lane_change_reward': False, 'on_road_reward': np.True_}}
2025-08-17 21:04:43,757 - INFO - Simulation completed successfully
2025-08-17 21:04:43,760 - INFO - Created roundabout-v0 environment
2025-08-17 21:04:43,761 - INFO - RoundaboutCooperativePolicy initialized with roundabout-specific social laws
2025-08-17 21:04:43,761 - INFO - Created RoundaboutCooperativePolicy for ego vehicle
2025-08-17 21:04:43,764 - INFO - Starting simulation with RoundaboutCooperativePolicy for 1000 steps
2025-08-17 21:04:43,781 - INFO - Step 0/1000 completed
2025-08-17 21:04:44,495 - INFO - Simulation ended early at step 44 - terminated: False, truncated: True
2025-08-17 21:04:44,495 - INFO - Info: {'speed': 29.999999999999986, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': False, 'high_speed_reward': 1.0, 'lane_change_reward': False, 'on_road_reward': np.False_}}
2025-08-17 21:04:44,495 - INFO - Simulation completed successfully
2025-08-17 21:04:44,499 - INFO - Created roundabout-v0 environment
2025-08-17 21:04:44,499 - INFO - RoundaboutCooperativePolicy initialized with roundabout-specific social laws
2025-08-17 21:04:44,499 - INFO - Created RoundaboutCooperativePolicy for ego vehicle
2025-08-17 21:04:44,503 - INFO - Starting simulation with RoundaboutCooperativePolicy for 1000 steps
2025-08-17 21:04:44,520 - INFO - Step 0/1000 completed
2025-08-17 21:04:45,202 - INFO - Simulation ended early at step 44 - terminated: False, truncated: True
2025-08-17 21:04:45,202 - INFO - Info: {'speed': 29.999999999999986, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': False, 'high_speed_reward': 1.0, 'lane_change_reward': False, 'on_road_reward': np.False_}}
2025-08-17 21:04:45,202 - INFO - Simulation completed successfully
2025-08-17 21:04:45,211 - INFO - Created racetrack-v0 environment
2025-08-17 21:04:45,211 - INFO - RacetrackSelfishPolicy initialized with aggressive racing parameters
2025-08-17 21:04:45,211 - INFO - Created RacetrackSelfishPolicy for ego vehicle
