2025-08-25 13:45:36,358 - INFO - Running 10 runs for intersection scenario with selfish composition
2025-08-25 13:45:36,379 - INFO - Created intersection-v1 environment
2025-08-25 13:45:36,379 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:36,404 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 13:45:36,404 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:36,404 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:36,446 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:36,460 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:36,460 - INFO - Step 0/1000 completed
2025-08-25 13:45:36,521 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:36,521 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:36,521 - INFO - Simulation completed successfully
2025-08-25 13:45:36,540 - INFO - Created intersection-v1 environment
2025-08-25 13:45:36,540 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:36,580 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 13:45:36,580 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:36,580 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:36,598 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:36,606 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:36,606 - INFO - Step 0/1000 completed
2025-08-25 13:45:36,616 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 13:45:36,616 - INFO - Info: {'speed': 22.873389410778522, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.7873389410778522), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.07873389410778524),), 'agents_terminated': (True,)}
2025-08-25 13:45:36,616 - INFO - Simulation completed successfully
2025-08-25 13:45:36,629 - INFO - Created intersection-v1 environment
2025-08-25 13:45:36,629 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:36,669 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 13:45:36,669 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:36,669 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:36,710 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:36,731 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:36,731 - INFO - Step 0/1000 completed
2025-08-25 13:45:36,753 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 13:45:36,753 - INFO - Info: {'speed': 12.756484381426949, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:36,753 - INFO - Simulation completed successfully
2025-08-25 13:45:36,787 - INFO - Created intersection-v1 environment
2025-08-25 13:45:36,787 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:36,819 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 13:45:36,819 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:36,819 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:36,837 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:36,848 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:36,848 - INFO - Step 0/1000 completed
2025-08-25 13:45:36,894 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:36,894 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:36,894 - INFO - Simulation completed successfully
2025-08-25 13:45:36,944 - INFO - Created intersection-v1 environment
2025-08-25 13:45:36,944 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:36,968 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 13:45:36,968 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:36,968 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:37,008 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:37,022 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:37,022 - INFO - Step 0/1000 completed
2025-08-25 13:45:37,054 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 13:45:37,054 - INFO - Info: {'speed': 12.455717242730856, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 13:45:37,054 - INFO - Simulation completed successfully
2025-08-25 13:45:37,096 - INFO - Created intersection-v1 environment
2025-08-25 13:45:37,096 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:37,120 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 13:45:37,120 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:37,120 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:37,138 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:37,150 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:37,150 - INFO - Step 0/1000 completed
2025-08-25 13:45:37,201 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:37,201 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:37,202 - INFO - Simulation completed successfully
2025-08-25 13:45:37,228 - INFO - Created intersection-v1 environment
2025-08-25 13:45:37,228 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:37,253 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 13:45:37,253 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:37,253 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:37,284 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:37,293 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:37,293 - INFO - Step 0/1000 completed
2025-08-25 13:45:37,325 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:37,325 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:37,325 - INFO - Simulation completed successfully
2025-08-25 13:45:37,359 - INFO - Created intersection-v1 environment
2025-08-25 13:45:37,359 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:37,384 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 13:45:37,384 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:37,384 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:37,409 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:37,421 - INFO - [EGO] step=0 speed=4.4408045811768035 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 13:45:37,421 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 13:45:37,421 - INFO - Info: {'speed': 4.4408045811768035, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:37,421 - INFO - Simulation completed successfully
2025-08-25 13:45:37,456 - INFO - Created intersection-v1 environment
2025-08-25 13:45:37,456 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:37,498 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 13:45:37,498 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:37,498 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:37,547 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:37,568 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:37,568 - INFO - Step 0/1000 completed
2025-08-25 13:45:37,593 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 13:45:37,594 - INFO - Info: {'speed': 14.80764637164484, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:37,594 - INFO - Simulation completed successfully
2025-08-25 13:45:37,613 - INFO - Created intersection-v1 environment
2025-08-25 13:45:37,613 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:37,638 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 13:45:37,638 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:37,638 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 13:45:37,662 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:37,677 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:37,677 - INFO - Step 0/1000 completed
2025-08-25 13:45:37,731 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:37,731 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:37,731 - INFO - Simulation completed successfully
2025-08-25 13:45:37,731 - INFO - Running 10 runs for intersection scenario with cooperative composition
2025-08-25 13:45:37,764 - INFO - Created intersection-v1 environment
2025-08-25 13:45:37,764 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:37,789 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:37,789 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:37,789 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:37,829 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:37,843 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:37,843 - INFO - Step 0/1000 completed
2025-08-25 13:45:37,926 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 13:45:37,926 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:37,926 - INFO - Simulation completed successfully
2025-08-25 13:45:37,977 - INFO - Created intersection-v1 environment
2025-08-25 13:45:37,977 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,017 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,017 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,017 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:38,034 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:38,043 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:38,043 - INFO - Step 0/1000 completed
2025-08-25 13:45:38,061 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 13:45:38,061 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:38,061 - INFO - Simulation completed successfully
2025-08-25 13:45:38,112 - INFO - Created intersection-v1 environment
2025-08-25 13:45:38,112 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,151 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,152 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,152 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:38,192 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:38,213 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:38,213 - INFO - Step 0/1000 completed
2025-08-25 13:45:38,235 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 13:45:38,235 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:38,235 - INFO - Simulation completed successfully
2025-08-25 13:45:38,255 - INFO - Created intersection-v1 environment
2025-08-25 13:45:38,255 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,286 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,286 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,286 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:38,304 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:38,315 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:38,315 - INFO - Step 0/1000 completed
2025-08-25 13:45:38,380 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 13:45:38,380 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:38,381 - INFO - Simulation completed successfully
2025-08-25 13:45:38,413 - INFO - Created intersection-v1 environment
2025-08-25 13:45:38,414 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,438 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,438 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,439 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:38,481 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:38,495 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:38,495 - INFO - Step 0/1000 completed
2025-08-25 13:45:38,529 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 13:45:38,529 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 13:45:38,529 - INFO - Simulation completed successfully
2025-08-25 13:45:38,544 - INFO - Created intersection-v1 environment
2025-08-25 13:45:38,544 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,570 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,570 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,570 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:38,589 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:38,601 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:38,601 - INFO - Step 0/1000 completed
2025-08-25 13:45:38,678 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 13:45:38,678 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:38,678 - INFO - Simulation completed successfully
2025-08-25 13:45:38,723 - INFO - Created intersection-v1 environment
2025-08-25 13:45:38,723 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,749 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,749 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,749 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:38,783 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:38,792 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:38,792 - INFO - Step 0/1000 completed
2025-08-25 13:45:38,837 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 13:45:38,837 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:38,837 - INFO - Simulation completed successfully
2025-08-25 13:45:38,865 - INFO - Created intersection-v1 environment
2025-08-25 13:45:38,865 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,891 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,892 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,892 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:38,916 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:38,929 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 13:45:38,929 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 13:45:38,930 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:38,930 - INFO - Simulation completed successfully
2025-08-25 13:45:38,956 - INFO - Created intersection-v1 environment
2025-08-25 13:45:38,956 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:38,997 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:38,997 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:38,997 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:39,048 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:39,068 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:39,069 - INFO - Step 0/1000 completed
2025-08-25 13:45:39,093 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 13:45:39,094 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 13:45:39,094 - INFO - Simulation completed successfully
2025-08-25 13:45:39,136 - INFO - Created intersection-v1 environment
2025-08-25 13:45:39,136 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:39,161 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 13:45:39,161 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:39,161 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 13:45:39,187 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:39,203 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:39,203 - INFO - Step 0/1000 completed
2025-08-25 13:45:39,243 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 13:45:39,243 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 13:45:39,243 - INFO - Simulation completed successfully
2025-08-25 13:45:39,243 - INFO - Running 10 runs for intersection scenario with mixed composition
2025-08-25 13:45:39,264 - INFO - Created intersection-v1 environment
2025-08-25 13:45:39,264 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:39,290 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 13:45:39,290 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:39,290 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 13:45:39,334 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:39,349 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:39,349 - INFO - Step 0/1000 completed
2025-08-25 13:45:39,414 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:39,414 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:39,415 - INFO - Simulation completed successfully
2025-08-25 13:45:39,429 - INFO - Created intersection-v1 environment
2025-08-25 13:45:39,429 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:39,474 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 13:45:39,474 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:39,474 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 13:45:39,495 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:39,505 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:39,505 - INFO - Step 0/1000 completed
2025-08-25 13:45:39,526 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 13:45:39,526 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:39,527 - INFO - Simulation completed successfully
2025-08-25 13:45:39,561 - INFO - Created intersection-v1 environment
2025-08-25 13:45:39,561 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:39,601 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 13:45:39,601 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:39,601 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 13:45:39,643 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:39,664 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:39,664 - INFO - Step 0/1000 completed
2025-08-25 13:45:39,686 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 13:45:39,686 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:39,686 - INFO - Simulation completed successfully
2025-08-25 13:45:39,720 - INFO - Created intersection-v1 environment
2025-08-25 13:45:39,720 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:39,752 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 13:45:39,752 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:39,752 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 13:45:39,769 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:39,780 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:39,781 - INFO - Step 0/1000 completed
2025-08-25 13:45:39,846 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 13:45:39,846 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:39,846 - INFO - Simulation completed successfully
2025-08-25 13:45:39,906 - INFO - Created intersection-v1 environment
2025-08-25 13:45:39,907 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:39,930 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 13:45:39,930 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:39,930 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 13:45:39,970 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:39,984 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:39,984 - INFO - Step 0/1000 completed
2025-08-25 13:45:40,015 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 13:45:40,015 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 13:45:40,016 - INFO - Simulation completed successfully
2025-08-25 13:45:40,049 - INFO - Created intersection-v1 environment
2025-08-25 13:45:40,049 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:40,073 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 13:45:40,074 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:40,074 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 13:45:40,091 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:40,102 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:40,102 - INFO - Step 0/1000 completed
2025-08-25 13:45:40,153 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:40,153 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:40,153 - INFO - Simulation completed successfully
2025-08-25 13:45:40,204 - INFO - Created intersection-v1 environment
2025-08-25 13:45:40,205 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:40,229 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 13:45:40,229 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:40,229 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 13:45:40,261 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:40,269 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:40,269 - INFO - Step 0/1000 completed
2025-08-25 13:45:40,312 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 13:45:40,312 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:40,312 - INFO - Simulation completed successfully
2025-08-25 13:45:40,355 - INFO - Created intersection-v1 environment
2025-08-25 13:45:40,355 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:40,380 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 13:45:40,380 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:40,380 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 13:45:40,404 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:40,417 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 13:45:40,417 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 13:45:40,417 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:40,417 - INFO - Simulation completed successfully
2025-08-25 13:45:40,436 - INFO - Created intersection-v1 environment
2025-08-25 13:45:40,436 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:40,477 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 13:45:40,477 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 13:45:40,477 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 13:45:40,527 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:40,547 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:40,547 - INFO - Step 0/1000 completed
2025-08-25 13:45:40,572 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 13:45:40,572 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 13:45:40,573 - INFO - Simulation completed successfully
2025-08-25 13:45:40,606 - INFO - Created intersection-v1 environment
2025-08-25 13:45:40,606 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 13:45:40,631 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 13:45:40,631 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 13:45:40,631 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 13:45:40,655 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 13:45:40,669 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 13:45:40,669 - INFO - Step 0/1000 completed
2025-08-25 13:45:40,723 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 13:45:40,723 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 13:45:40,723 - INFO - Simulation completed successfully
2025-08-25 13:45:40,723 - INFO - Saving aggregated results...
2025-08-25 13:45:40,734 - INFO - Aggregated results saved to results/highway_stats.csv
2025-08-25 13:45:40,734 - INFO - Generating comparison plots...
2025-08-25 13:45:43,578 - INFO - Generated 6 plots in /Users/shayvasilisky/Documents/Personal/TASP/Second Year/Semester B/רובוטים קוגניטיביים/Project CC_V2/social_law_simulation/plots
2025-08-25 13:45:43,578 - INFO -   - intersection_average_speed.png
2025-08-25 13:45:43,578 - INFO -   - intersection_collisions.png
2025-08-25 13:45:43,578 - INFO -   - intersection_acceleration_stability.png
2025-08-25 13:45:43,578 - INFO -   - combined_efficiency_comparison.png
2025-08-25 13:45:43,578 - INFO -   - combined_safety_comparison.png
2025-08-25 13:45:43,578 - INFO -   - summary_dashboard.png
