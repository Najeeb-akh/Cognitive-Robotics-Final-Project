2025-08-25 14:16:58,082 - INFO - Running 10 runs for intersection scenario with selfish composition
2025-08-25 14:16:58,122 - INFO - Created intersection-v1 environment
2025-08-25 14:16:58,122 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:58,122 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:58,151 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:16:58,151 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:58,151 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:58,194 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:58,210 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:58,210 - INFO - Step 0/1000 completed
2025-08-25 14:16:58,276 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:16:58,277 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:58,278 - INFO - Simulation completed successfully
2025-08-25 14:16:58,325 - INFO - Created intersection-v1 environment
2025-08-25 14:16:58,325 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:58,325 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:58,371 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:16:58,371 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:58,371 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:58,390 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:58,400 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:58,400 - INFO - Step 0/1000 completed
2025-08-25 14:16:58,411 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:16:58,411 - INFO - Info: {'speed': 22.873389410778522, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.7873389410778522), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.07873389410778524),), 'agents_terminated': (True,)}
2025-08-25 14:16:58,411 - INFO - Simulation completed successfully
2025-08-25 14:16:58,440 - INFO - Created intersection-v1 environment
2025-08-25 14:16:58,440 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:58,440 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:58,483 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:16:58,483 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:58,483 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:58,527 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:58,549 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:58,549 - INFO - Step 0/1000 completed
2025-08-25 14:16:58,572 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:16:58,572 - INFO - Info: {'speed': 12.756484381426949, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:58,573 - INFO - Simulation completed successfully
2025-08-25 14:16:58,616 - INFO - Created intersection-v1 environment
2025-08-25 14:16:58,616 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:58,617 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:58,650 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:16:58,650 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:58,650 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:58,669 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:58,682 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:58,683 - INFO - Step 0/1000 completed
2025-08-25 14:16:58,734 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:16:58,734 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:58,734 - INFO - Simulation completed successfully
2025-08-25 14:16:58,757 - INFO - Created intersection-v1 environment
2025-08-25 14:16:58,757 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:58,757 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:58,784 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:16:58,784 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:58,784 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:58,828 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:58,844 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:58,844 - INFO - Step 0/1000 completed
2025-08-25 14:16:58,879 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:16:58,879 - INFO - Info: {'speed': 12.455717242730856, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:16:58,880 - INFO - Simulation completed successfully
2025-08-25 14:16:58,923 - INFO - Created intersection-v1 environment
2025-08-25 14:16:58,923 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:58,923 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:58,950 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:16:58,950 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:58,950 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:58,968 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:58,981 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:58,981 - INFO - Step 0/1000 completed
2025-08-25 14:16:59,035 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:16:59,035 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:59,036 - INFO - Simulation completed successfully
2025-08-25 14:16:59,071 - INFO - Created intersection-v1 environment
2025-08-25 14:16:59,071 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:59,071 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:59,098 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:16:59,099 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:59,099 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:59,133 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:59,143 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:59,143 - INFO - Step 0/1000 completed
2025-08-25 14:16:59,178 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:16:59,178 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:59,178 - INFO - Simulation completed successfully
2025-08-25 14:16:59,215 - INFO - Created intersection-v1 environment
2025-08-25 14:16:59,215 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:59,215 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:59,244 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:16:59,244 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:59,244 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:59,271 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:59,285 - INFO - [EGO] step=0 speed=4.4408045811768035 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:16:59,285 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:16:59,285 - INFO - Info: {'speed': 4.4408045811768035, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:59,285 - INFO - Simulation completed successfully
2025-08-25 14:16:59,313 - INFO - Created intersection-v1 environment
2025-08-25 14:16:59,313 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:59,313 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:59,358 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:16:59,358 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:59,358 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:59,411 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:59,433 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:59,433 - INFO - Step 0/1000 completed
2025-08-25 14:16:59,459 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:16:59,459 - INFO - Info: {'speed': 14.80764637164484, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:59,460 - INFO - Simulation completed successfully
2025-08-25 14:16:59,504 - INFO - Created intersection-v1 environment
2025-08-25 14:16:59,504 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:59,504 - INFO - Applied class-level overrides for selfish: TIME_WANTED=1.5, POLITENESS=0.1
2025-08-25 14:16:59,531 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:16:59,531 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:16:59,531 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:16:59,557 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:59,572 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:59,572 - INFO - Step 0/1000 completed
2025-08-25 14:16:59,631 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:16:59,631 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:59,632 - INFO - Simulation completed successfully
2025-08-25 14:16:59,632 - INFO - Running 10 runs for intersection scenario with cooperative composition
2025-08-25 14:16:59,669 - INFO - Created intersection-v1 environment
2025-08-25 14:16:59,669 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:59,669 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:16:59,697 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:16:59,697 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:16:59,697 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:16:59,741 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:59,756 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:59,756 - INFO - Step 0/1000 completed
2025-08-25 14:16:59,846 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:16:59,846 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:59,847 - INFO - Simulation completed successfully
2025-08-25 14:16:59,892 - INFO - Created intersection-v1 environment
2025-08-25 14:16:59,892 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:16:59,892 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:16:59,935 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:16:59,935 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:16:59,936 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:16:59,955 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:16:59,965 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:16:59,965 - INFO - Step 0/1000 completed
2025-08-25 14:16:59,985 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:16:59,985 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:16:59,986 - INFO - Simulation completed successfully
2025-08-25 14:17:00,034 - INFO - Created intersection-v1 environment
2025-08-25 14:17:00,034 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:00,034 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:00,079 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:00,080 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:00,080 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:00,122 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:00,145 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:00,145 - INFO - Step 0/1000 completed
2025-08-25 14:17:00,169 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:17:00,169 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:00,169 - INFO - Simulation completed successfully
2025-08-25 14:17:00,206 - INFO - Created intersection-v1 environment
2025-08-25 14:17:00,206 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:00,206 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:00,242 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:00,242 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:00,242 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:00,261 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:00,274 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:00,274 - INFO - Step 0/1000 completed
2025-08-25 14:17:00,337 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:17:00,337 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:00,338 - INFO - Simulation completed successfully
2025-08-25 14:17:00,370 - INFO - Created intersection-v1 environment
2025-08-25 14:17:00,370 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:00,371 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:00,401 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:00,401 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:00,401 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:00,444 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:00,458 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:00,458 - INFO - Step 0/1000 completed
2025-08-25 14:17:00,493 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:17:00,494 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 14:17:00,494 - INFO - Simulation completed successfully
2025-08-25 14:17:00,523 - INFO - Created intersection-v1 environment
2025-08-25 14:17:00,523 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:00,523 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:00,555 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:00,555 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:00,555 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:00,574 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:00,586 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:00,586 - INFO - Step 0/1000 completed
2025-08-25 14:17:00,669 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:17:00,669 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:00,669 - INFO - Simulation completed successfully
2025-08-25 14:17:00,691 - INFO - Created intersection-v1 environment
2025-08-25 14:17:00,691 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:00,691 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:00,717 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:00,717 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:00,718 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:00,752 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:00,761 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:00,761 - INFO - Step 0/1000 completed
2025-08-25 14:17:00,807 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:17:00,807 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:00,807 - INFO - Simulation completed successfully
2025-08-25 14:17:00,822 - INFO - Created intersection-v1 environment
2025-08-25 14:17:00,822 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:00,822 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:00,849 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:00,849 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:00,849 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:00,875 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:00,888 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:17:00,888 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:17:00,889 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:00,889 - INFO - Simulation completed successfully
2025-08-25 14:17:00,917 - INFO - Created intersection-v1 environment
2025-08-25 14:17:00,917 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:00,917 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:00,961 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:00,961 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:00,961 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:01,013 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:01,035 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:01,035 - INFO - Step 0/1000 completed
2025-08-25 14:17:01,063 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:17:01,063 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:17:01,064 - INFO - Simulation completed successfully
2025-08-25 14:17:01,093 - INFO - Created intersection-v1 environment
2025-08-25 14:17:01,093 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:01,093 - INFO - Applied class-level overrides for cooperative: TIME_WANTED=2.0, POLITENESS=0.6
2025-08-25 14:17:01,120 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:17:01,120 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:01,120 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:17:01,148 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:01,166 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:01,166 - INFO - Step 0/1000 completed
2025-08-25 14:17:01,213 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:17:01,213 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(0.0)}, 'agents_rewards': (np.float64(0.6666666666666666),), 'agents_terminated': (True,)}
2025-08-25 14:17:01,214 - INFO - Simulation completed successfully
2025-08-25 14:17:01,214 - INFO - Running 10 runs for intersection scenario with mixed composition
2025-08-25 14:17:01,276 - INFO - Created intersection-v1 environment
2025-08-25 14:17:01,276 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:01,276 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:01,308 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:17:01,308 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:17:01,308 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:17:01,357 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:01,376 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:01,376 - INFO - Step 0/1000 completed
2025-08-25 14:17:01,451 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:17:01,451 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:01,452 - INFO - Simulation completed successfully
2025-08-25 14:17:01,501 - INFO - Created intersection-v1 environment
2025-08-25 14:17:01,501 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:01,501 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:01,548 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:17:01,548 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:01,548 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:17:01,567 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:01,577 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:01,577 - INFO - Step 0/1000 completed
2025-08-25 14:17:01,597 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:17:01,597 - INFO - Info: {'speed': 8.649572041118859, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:01,597 - INFO - Simulation completed successfully
2025-08-25 14:17:01,625 - INFO - Created intersection-v1 environment
2025-08-25 14:17:01,625 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:01,625 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:01,669 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:17:01,669 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:01,669 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:17:01,712 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:01,735 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:01,735 - INFO - Step 0/1000 completed
2025-08-25 14:17:01,760 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:17:01,760 - INFO - Info: {'speed': 13.79220212581312, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:01,761 - INFO - Simulation completed successfully
2025-08-25 14:17:01,816 - INFO - Created intersection-v1 environment
2025-08-25 14:17:01,816 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:01,816 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:01,852 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:17:01,852 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:01,853 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:17:01,873 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:01,886 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:01,886 - INFO - Step 0/1000 completed
2025-08-25 14:17:01,938 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:17:01,938 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:01,938 - INFO - Simulation completed successfully
2025-08-25 14:17:01,966 - INFO - Created intersection-v1 environment
2025-08-25 14:17:01,966 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:01,966 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:01,996 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:17:01,996 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:01,996 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:17:02,042 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:02,058 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:02,058 - INFO - Step 0/1000 completed
2025-08-25 14:17:02,094 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:17:02,094 - INFO - Info: {'speed': 19.950095869871483, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.49500958698714825), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04950095869871481),), 'agents_terminated': (True,)}
2025-08-25 14:17:02,095 - INFO - Simulation completed successfully
2025-08-25 14:17:02,125 - INFO - Created intersection-v1 environment
2025-08-25 14:17:02,126 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:02,126 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:02,155 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:17:02,155 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:17:02,155 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:17:02,174 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:02,187 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:02,187 - INFO - Step 0/1000 completed
2025-08-25 14:17:02,245 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:17:02,246 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:02,246 - INFO - Simulation completed successfully
2025-08-25 14:17:02,276 - INFO - Created intersection-v1 environment
2025-08-25 14:17:02,276 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:02,276 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:02,303 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:17:02,303 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:02,303 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:17:02,339 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:02,348 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:02,348 - INFO - Step 0/1000 completed
2025-08-25 14:17:02,396 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:17:02,397 - INFO - Info: {'speed': 19.998542660230925, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49985426602309246), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:02,397 - INFO - Simulation completed successfully
2025-08-25 14:17:02,434 - INFO - Created intersection-v1 environment
2025-08-25 14:17:02,434 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:02,434 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:02,464 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:17:02,464 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:02,464 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:17:02,493 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:02,507 - INFO - [EGO] step=0 speed=4.2293376963588605 lane_index=('o0', 'ir0', 0) crashed=True
2025-08-25 14:17:02,508 - INFO - Simulation ended early at step 0 - terminated: True, truncated: False
2025-08-25 14:17:02,508 - INFO - Info: {'speed': 4.2293376963588605, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:02,508 - INFO - Simulation completed successfully
2025-08-25 14:17:02,537 - INFO - Created intersection-v1 environment
2025-08-25 14:17:02,537 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:02,537 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:02,584 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:17:02,584 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:17:02,584 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:17:02,639 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:02,662 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:02,662 - INFO - Step 0/1000 completed
2025-08-25 14:17:02,690 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:17:02,690 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:17:02,690 - INFO - Simulation completed successfully
2025-08-25 14:17:02,739 - INFO - Created intersection-v1 environment
2025-08-25 14:17:02,739 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:17:02,739 - INFO - Applied class-level overrides for mixed: TIME_WANTED=1.75, POLITENESS=0.35
2025-08-25 14:17:02,769 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:17:02,770 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:17:02,770 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:17:02,797 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:17:02,813 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:17:02,813 - INFO - Step 0/1000 completed
2025-08-25 14:17:02,872 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:17:02,873 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:17:02,873 - INFO - Simulation completed successfully
2025-08-25 14:17:02,873 - INFO - Saving aggregated results...
2025-08-25 14:17:02,883 - INFO - Aggregated results saved to results/highway_stats.csv
2025-08-25 14:17:02,883 - INFO - Generating comparison plots...
2025-08-25 14:17:05,206 - INFO - Generated 6 plots in /Users/shayvasilisky/Documents/Personal/TASP/Second Year/Semester B/רובוטים קוגניטיביים/Project CC_V2/social_law_simulation/plots
2025-08-25 14:17:05,206 - INFO -   - intersection_average_speed.png
2025-08-25 14:17:05,206 - INFO -   - intersection_collisions.png
2025-08-25 14:17:05,206 - INFO -   - intersection_acceleration_stability.png
2025-08-25 14:17:05,206 - INFO -   - combined_efficiency_comparison.png
2025-08-25 14:17:05,206 - INFO -   - combined_safety_comparison.png
2025-08-25 14:17:05,206 - INFO -   - summary_dashboard.png
