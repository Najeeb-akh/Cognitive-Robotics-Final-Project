2025-08-25 14:00:53,136 - INFO - Running 10 runs for intersection scenario with selfish composition
2025-08-25 14:00:53,195 - INFO - Created intersection-v1 environment
2025-08-25 14:00:53,195 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:53,240 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:00:53,240 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:53,240 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:53,284 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:53,298 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:53,299 - INFO - Step 0/1000 completed
2025-08-25 14:00:53,354 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:53,354 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:53,354 - INFO - Simulation completed successfully
2025-08-25 14:00:53,382 - INFO - Created intersection-v1 environment
2025-08-25 14:00:53,382 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:53,419 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/4 (composition=selfish)
2025-08-25 14:00:53,419 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:53,419 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:53,454 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:53,473 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:53,473 - INFO - Step 0/1000 completed
2025-08-25 14:00:53,532 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:53,532 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:53,532 - INFO - Simulation completed successfully
2025-08-25 14:00:53,562 - INFO - Created intersection-v1 environment
2025-08-25 14:00:53,562 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:53,608 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:00:53,608 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:53,608 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:53,627 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:53,638 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:53,638 - INFO - Step 0/1000 completed
2025-08-25 14:00:53,688 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:53,688 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:53,688 - INFO - Simulation completed successfully
2025-08-25 14:00:53,736 - INFO - Created intersection-v1 environment
2025-08-25 14:00:53,736 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:53,782 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/7 (composition=selfish)
2025-08-25 14:00:53,782 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:53,782 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:53,801 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:53,813 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:53,813 - INFO - Step 0/1000 completed
2025-08-25 14:00:53,864 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:53,864 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:53,864 - INFO - Simulation completed successfully
2025-08-25 14:00:53,908 - INFO - Created intersection-v1 environment
2025-08-25 14:00:53,908 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:53,951 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:00:53,951 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:53,951 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:53,984 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:54,002 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:54,002 - INFO - Step 0/1000 completed
2025-08-25 14:00:54,025 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:54,025 - INFO - Info: {'speed': 19.818837751309246, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.4818837751309246), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04818837751309246),), 'agents_terminated': (True,)}
2025-08-25 14:00:54,025 - INFO - Simulation completed successfully
2025-08-25 14:00:54,068 - INFO - Created intersection-v1 environment
2025-08-25 14:00:54,068 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:54,087 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/3 (composition=selfish)
2025-08-25 14:00:54,087 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:54,087 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:54,148 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:54,166 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:54,166 - INFO - Step 0/1000 completed
2025-08-25 14:00:54,188 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:54,188 - INFO - Info: {'speed': 24.561958168995417, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.9561958168995417), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.09561958168995417),), 'agents_terminated': (True,)}
2025-08-25 14:00:54,189 - INFO - Simulation completed successfully
2025-08-25 14:00:54,216 - INFO - Created intersection-v1 environment
2025-08-25 14:00:54,216 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:54,250 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:00:54,250 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:54,250 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:54,292 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:54,311 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:54,311 - INFO - Step 0/1000 completed
2025-08-25 14:00:54,330 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:54,330 - INFO - Info: {'speed': 19.818837751309246, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.4818837751309246), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04818837751309246),), 'agents_terminated': (True,)}
2025-08-25 14:00:54,331 - INFO - Simulation completed successfully
2025-08-25 14:00:54,376 - INFO - Created intersection-v1 environment
2025-08-25 14:00:54,376 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:54,419 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/6 (composition=selfish)
2025-08-25 14:00:54,420 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:54,420 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:54,446 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:54,458 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:54,458 - INFO - Step 0/1000 completed
2025-08-25 14:00:54,509 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:54,509 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:54,509 - INFO - Simulation completed successfully
2025-08-25 14:00:54,537 - INFO - Created intersection-v1 environment
2025-08-25 14:00:54,537 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:54,588 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/5 (composition=selfish)
2025-08-25 14:00:54,588 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:54,588 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:54,631 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:54,649 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:54,649 - INFO - Step 0/1000 completed
2025-08-25 14:00:54,723 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:54,723 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:54,723 - INFO - Simulation completed successfully
2025-08-25 14:00:54,759 - INFO - Created intersection-v1 environment
2025-08-25 14:00:54,759 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:54,777 - INFO - Population overrides: cooperative_set=0/0, baseline_set=0/3 (composition=selfish)
2025-08-25 14:00:54,777 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:54,777 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=1.0)
2025-08-25 14:00:54,828 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:54,850 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:54,850 - INFO - Step 0/1000 completed
2025-08-25 14:00:54,876 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:54,876 - INFO - Info: {'speed': 15.938712641708477, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.09387126417084772), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.00938712641708476),), 'agents_terminated': (True,)}
2025-08-25 14:00:54,876 - INFO - Simulation completed successfully
2025-08-25 14:00:54,876 - INFO - Running 10 runs for intersection scenario with cooperative composition
2025-08-25 14:00:54,920 - INFO - Created intersection-v1 environment
2025-08-25 14:00:54,920 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:54,963 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:54,963 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:54,963 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:55,004 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:55,019 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:55,019 - INFO - Step 0/1000 completed
2025-08-25 14:00:55,088 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:00:55,088 - INFO - Info: {'speed': 24.852528716562727, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9852528716562727), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:55,088 - INFO - Simulation completed successfully
2025-08-25 14:00:55,109 - INFO - Created intersection-v1 environment
2025-08-25 14:00:55,109 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:55,143 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:55,143 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:55,143 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:55,177 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:55,196 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:55,196 - INFO - Step 0/1000 completed
2025-08-25 14:00:55,252 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:55,252 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:55,253 - INFO - Simulation completed successfully
2025-08-25 14:00:55,281 - INFO - Created intersection-v1 environment
2025-08-25 14:00:55,281 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:55,324 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:55,324 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:55,324 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:55,342 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:55,351 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:55,351 - INFO - Step 0/1000 completed
2025-08-25 14:00:55,397 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:55,397 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:55,398 - INFO - Simulation completed successfully
2025-08-25 14:00:55,425 - INFO - Created intersection-v1 environment
2025-08-25 14:00:55,425 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:55,469 - INFO - Population overrides: cooperative_set=0/7, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:55,469 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:55,469 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:55,487 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:55,498 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:55,498 - INFO - Step 0/1000 completed
2025-08-25 14:00:55,546 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:55,546 - INFO - Info: {'speed': 19.991471971301785, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49914719713017847), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:55,546 - INFO - Simulation completed successfully
2025-08-25 14:00:55,600 - INFO - Created intersection-v1 environment
2025-08-25 14:00:55,600 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:55,642 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:55,643 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:55,643 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:55,676 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:55,694 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:55,694 - INFO - Step 0/1000 completed
2025-08-25 14:00:55,743 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:00:55,743 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:55,744 - INFO - Simulation completed successfully
2025-08-25 14:00:55,764 - INFO - Created intersection-v1 environment
2025-08-25 14:00:55,764 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:55,783 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:55,783 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:55,783 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:55,844 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:55,862 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:55,862 - INFO - Step 0/1000 completed
2025-08-25 14:00:55,911 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:00:55,911 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:55,911 - INFO - Simulation completed successfully
2025-08-25 14:00:55,932 - INFO - Created intersection-v1 environment
2025-08-25 14:00:55,932 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:55,967 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:55,967 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:55,967 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:56,009 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:56,027 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:56,027 - INFO - Step 0/1000 completed
2025-08-25 14:00:56,070 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:00:56,070 - INFO - Info: {'speed': 7.725467974079904, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:56,070 - INFO - Simulation completed successfully
2025-08-25 14:00:56,098 - INFO - Created intersection-v1 environment
2025-08-25 14:00:56,098 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:56,140 - INFO - Population overrides: cooperative_set=0/6, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:56,140 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:56,140 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:56,166 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:56,178 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:56,178 - INFO - Step 0/1000 completed
2025-08-25 14:00:56,211 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:00:56,211 - INFO - Info: {'speed': 14.101220212980753, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:56,211 - INFO - Simulation completed successfully
2025-08-25 14:00:56,255 - INFO - Created intersection-v1 environment
2025-08-25 14:00:56,255 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:56,315 - INFO - Population overrides: cooperative_set=0/5, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:56,315 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:56,315 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:56,363 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:56,381 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:56,381 - INFO - Step 0/1000 completed
2025-08-25 14:00:56,487 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:00:56,487 - INFO - Info: {'speed': 24.852528716562727, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9852528716562727), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:56,487 - INFO - Simulation completed successfully
2025-08-25 14:00:56,508 - INFO - Created intersection-v1 environment
2025-08-25 14:00:56,508 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:56,528 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/0 (composition=cooperative)
2025-08-25 14:00:56,528 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:56,528 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.0)
2025-08-25 14:00:56,581 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:56,603 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:56,603 - INFO - Step 0/1000 completed
2025-08-25 14:00:56,630 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:56,631 - INFO - Info: {'speed': 18.36003738496346, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.33600373849634585), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.03360037384963458),), 'agents_terminated': (True,)}
2025-08-25 14:00:56,631 - INFO - Simulation completed successfully
2025-08-25 14:00:56,631 - INFO - Running 10 runs for intersection scenario with mixed composition
2025-08-25 14:00:56,652 - INFO - Created intersection-v1 environment
2025-08-25 14:00:56,652 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:56,696 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:00:56,696 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:56,696 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:00:56,739 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:56,755 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:56,755 - INFO - Step 0/1000 completed
2025-08-25 14:00:56,829 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:00:56,829 - INFO - Info: {'speed': 24.852528716562727, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9852528716562727), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:56,830 - INFO - Simulation completed successfully
2025-08-25 14:00:56,864 - INFO - Created intersection-v1 environment
2025-08-25 14:00:56,865 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:56,901 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/2 (composition=mixed)
2025-08-25 14:00:56,902 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:56,902 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:00:56,937 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:56,955 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:56,955 - INFO - Step 0/1000 completed
2025-08-25 14:00:57,013 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:57,013 - INFO - Info: {'speed': 24.137030798171082, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9137030798171082), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:57,013 - INFO - Simulation completed successfully
2025-08-25 14:00:57,040 - INFO - Created intersection-v1 environment
2025-08-25 14:00:57,040 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:57,084 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:00:57,084 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:57,084 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:00:57,102 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:57,111 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:57,112 - INFO - Step 0/1000 completed
2025-08-25 14:00:57,158 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:57,158 - INFO - Info: {'speed': 29.841194013284483, 'crashed': False, 'action': 3, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(1.0), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:57,158 - INFO - Simulation completed successfully
2025-08-25 14:00:57,185 - INFO - Created intersection-v1 environment
2025-08-25 14:00:57,185 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:57,230 - INFO - Population overrides: cooperative_set=0/4, baseline_set=0/3 (composition=mixed)
2025-08-25 14:00:57,230 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:57,230 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:00:57,250 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:57,264 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:57,264 - INFO - Step 0/1000 completed
2025-08-25 14:00:57,326 - INFO - Simulation ended early at step 3 - terminated: True, truncated: False
2025-08-25 14:00:57,326 - INFO - Info: {'speed': 19.991471971301785, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.49914719713017847), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:57,327 - INFO - Simulation completed successfully
2025-08-25 14:00:57,352 - INFO - Created intersection-v1 environment
2025-08-25 14:00:57,352 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:57,402 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:00:57,402 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:57,403 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:00:57,441 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:57,461 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:57,461 - INFO - Step 0/1000 completed
2025-08-25 14:00:57,515 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:00:57,515 - INFO - Info: {'speed': 9.278067740220912, 'crashed': True, 'action': 4, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:57,515 - INFO - Simulation completed successfully
2025-08-25 14:00:57,548 - INFO - Created intersection-v1 environment
2025-08-25 14:00:57,549 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:57,572 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/1 (composition=mixed)
2025-08-25 14:00:57,572 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:57,572 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:00:57,644 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:57,667 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:57,667 - INFO - Step 0/1000 completed
2025-08-25 14:00:57,690 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:57,690 - INFO - Info: {'speed': 24.561958168995417, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.9561958168995417), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.09561958168995417),), 'agents_terminated': (True,)}
2025-08-25 14:00:57,690 - INFO - Simulation completed successfully
2025-08-25 14:00:57,711 - INFO - Created intersection-v1 environment
2025-08-25 14:00:57,712 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:57,746 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:00:57,746 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:57,746 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:00:57,789 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:57,807 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:57,807 - INFO - Step 0/1000 completed
2025-08-25 14:00:57,827 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:57,827 - INFO - Info: {'speed': 19.818837751309246, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.4818837751309246), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.04818837751309246),), 'agents_terminated': (True,)}
2025-08-25 14:00:57,827 - INFO - Simulation completed successfully
2025-08-25 14:00:57,872 - INFO - Created intersection-v1 environment
2025-08-25 14:00:57,872 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:57,915 - INFO - Population overrides: cooperative_set=0/3, baseline_set=0/3 (composition=mixed)
2025-08-25 14:00:57,915 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:57,915 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:00:57,942 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:57,954 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:57,954 - INFO - Step 0/1000 completed
2025-08-25 14:00:57,987 - INFO - Simulation ended early at step 2 - terminated: True, truncated: False
2025-08-25 14:00:57,987 - INFO - Info: {'speed': 14.101220212980753, 'crashed': True, 'action': 0, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.0), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:57,987 - INFO - Simulation completed successfully
2025-08-25 14:00:58,015 - INFO - Created intersection-v1 environment
2025-08-25 14:00:58,015 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:58,066 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/3 (composition=mixed)
2025-08-25 14:00:58,066 - INFO - IntersectionCooperativePolicy initialized with intersection-specific social laws
2025-08-25 14:00:58,066 - INFO - Ego policy: IntersectionCooperativePolicy (selfish_ratio=0.5)
2025-08-25 14:00:58,108 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:58,126 - INFO - [EGO] step=0 speed=18.2911176537386 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:58,127 - INFO - Step 0/1000 completed
2025-08-25 14:00:58,232 - INFO - Simulation ended early at step 4 - terminated: True, truncated: False
2025-08-25 14:00:58,232 - INFO - Info: {'speed': 24.852528716562727, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'high_speed_reward': np.float64(0.9852528716562727), 'arrived_reward': 1.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(1.0),), 'agents_terminated': (True,)}
2025-08-25 14:00:58,232 - INFO - Simulation completed successfully
2025-08-25 14:00:58,267 - INFO - Created intersection-v1 environment
2025-08-25 14:00:58,267 - WARNING - Observation features not specified; proceeding with default assumptions (got: None)
2025-08-25 14:00:58,286 - INFO - Population overrides: cooperative_set=0/2, baseline_set=0/1 (composition=mixed)
2025-08-25 14:00:58,286 - INFO - IntersectionSelfishPolicy initialized with intersection-specific parameters
2025-08-25 14:00:58,286 - INFO - Ego policy: IntersectionSelfishPolicy (selfish_ratio=0.5)
2025-08-25 14:00:58,337 - INFO - Starting simulation with DiscreteActionAdapter for 1000 steps
2025-08-25 14:00:58,358 - INFO - [EGO] step=0 speed=22.436676480607897 lane_index=('o0', 'ir0', 0) crashed=False
2025-08-25 14:00:58,358 - INFO - Step 0/1000 completed
2025-08-25 14:00:58,385 - INFO - Simulation ended early at step 1 - terminated: True, truncated: False
2025-08-25 14:00:58,385 - INFO - Info: {'speed': 15.938712641708477, 'crashed': True, 'action': 3, 'rewards': {'collision_reward': 1.0, 'high_speed_reward': np.float64(0.09387126417084772), 'arrived_reward': 0.0, 'on_road_reward': np.float64(1.0)}, 'agents_rewards': (np.float64(0.00938712641708476),), 'agents_terminated': (True,)}
2025-08-25 14:00:58,385 - INFO - Simulation completed successfully
2025-08-25 14:00:58,385 - INFO - Saving aggregated results...
2025-08-25 14:00:58,394 - INFO - Aggregated results saved to results/highway_stats.csv
2025-08-25 14:00:58,394 - INFO - Generating comparison plots...
2025-08-25 14:01:00,344 - INFO - Generated 6 plots in /Users/shayvasilisky/Documents/Personal/TASP/Second Year/Semester B/רובוטים קוגניטיביים/Project CC_V2/social_law_simulation/plots
2025-08-25 14:01:00,344 - INFO -   - intersection_average_speed.png
2025-08-25 14:01:00,344 - INFO -   - intersection_collisions.png
2025-08-25 14:01:00,344 - INFO -   - intersection_acceleration_stability.png
2025-08-25 14:01:00,344 - INFO -   - combined_efficiency_comparison.png
2025-08-25 14:01:00,344 - INFO -   - combined_safety_comparison.png
2025-08-25 14:01:00,344 - INFO -   - summary_dashboard.png
